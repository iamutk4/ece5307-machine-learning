{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handcrafted Fully Connected Neural Net (FCNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data\n",
    "Xtr_loadpath = 'Xtr.csv'\n",
    "Xts_loadpath = 'Xts.csv'\n",
    "ytr_loadpath = 'ytr.csv'\n",
    "\n",
    "Xtr = np.loadtxt(Xtr_loadpath, delimiter=\",\")\n",
    "Xts = np.loadtxt(Xts_loadpath, delimiter=\",\")\n",
    "ytr = np.loadtxt(ytr_loadpath, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardizing the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model was tested with both standardization, and normalization. Normalization doesn't seem to \n",
    "# give good results, that's why we finalized our design with standardization. \n",
    "# standardize the training data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scale= StandardScaler()\n",
    "\n",
    "Xtr_standardized = scale.fit_transform(Xtr) # revise this line as needed\n",
    "Xts_standardized = scale.fit_transform(Xts) # revise this line as needed\n",
    "ytr_standardized = ytr # revise this line as needed\n",
    "\n",
    "Xtr_torch = torch.Tensor(Xtr_standardized)\n",
    "Xts_torch = torch.Tensor(Xts_standardized)\n",
    "ytr_torch = torch.Tensor(ytr_standardized)\n",
    "\n",
    "# save the standardized training data\n",
    "Xtr_savepath = 'Xtr_pytorch.csv'\n",
    "Xts_savepath = 'Xts_pytorch.csv'\n",
    "ytr_savepath = 'ytr_pytorch.csv'\n",
    "yts_hat_savepath = 'yts_hat_pytorch.csv'\n",
    "\n",
    "np.savetxt(Xtr_savepath, Xtr_standardized, delimiter=\",\")\n",
    "np.savetxt(Xts_savepath, Xts_standardized, delimiter=\",\")\n",
    "np.savetxt(ytr_savepath, ytr_standardized, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split, and Creation of Pytorch Dataloaders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(Xtr_torch,ytr_torch,test_size=0.2,random_state = random.randint(0,1000))\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "test_ds =  TensorDataset(x_test, y_test)\n",
    "batch_size = 32\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "test_dl = DataLoader(test_ds, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handcrafted Model CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG16(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv1d(1, 32, kernel_size=(2,), stride=(1,), padding=(1,))\n",
      "    (1): Dropout(p=0.2, inplace=False)\n",
      "    (2): Sigmoid()\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv1d(32, 10, kernel_size=(1,), stride=(1,))\n",
      "    (1): Sigmoid()\n",
      "    (2): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=90, out_features=90, bias=True)\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      "  (fc1): Sequential(\n",
      "    (0): Linear(in_features=90, out_features=85, bias=True)\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      "  (fc2): Sequential(\n",
      "    (0): Linear(in_features=85, out_features=85, bias=True)\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      "  (fc3): Sequential(\n",
      "    (0): Linear(in_features=85, out_features=1, bias=True)\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class VGG16(nn.Module):\n",
    "    def __init__(self, num_classes=1):\n",
    "        super(VGG16, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1,out_channels=32, kernel_size=2, stride=1, padding=1),\n",
    "#             nn.BatchNorm1d(5),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Sigmoid())\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=32, out_channels=10, kernel_size=1, stride=1, padding=0),\n",
    "#             nn.BatchNorm1d(10),\n",
    "            nn.Sigmoid(), \n",
    "            nn.MaxPool1d(kernel_size = 1, stride = 1))\n",
    "        self.fc = nn.Sequential(\n",
    "#             nn.Dropout(0.5),\n",
    "            nn.Linear(90, 90),\n",
    "            nn.Sigmoid())\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(90, 85),\n",
    "#             nn.Dropout(0.5),\n",
    "            nn.Sigmoid())\n",
    "        self.fc2= nn.Sequential(\n",
    "            nn.Linear(85, 85),\n",
    "            nn.Sigmoid())\n",
    "        self.fc3= nn.Sequential(\n",
    "            nn.Linear(85, 1),\n",
    "            nn.Sigmoid())\n",
    "    def forward(self, x):\n",
    "#         print(x.shape)\n",
    "        out = self.layer1(x)\n",
    "#         print(\"Layer1: \",out.shape)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "#         print(\"Layer2: \",out.shape)\n",
    "        out = self.fc(out)\n",
    "#         print(\"FC1: \",out.shape)\n",
    "        out = self.fc1(out)\n",
    "#         print(\"FC2: \",out.shape)\n",
    "        out = self.fc2(out)\n",
    "#         print(\"FC3: \",out.shape)\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "model_vgg = VGG16(num_classes=1)\n",
    "print(str(model_vgg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg = VGG16(num_classes=1)\n",
    "x_train,x_test,y_train,y_test = train_test_split(Xtr_torch,ytr_torch,test_size=0.2,random_state = 42)\n",
    "x_train = x_train.reshape(x_train.shape[0],x_train.shape[1],1).permute(0,2,1)\n",
    "y_train = y_train.reshape(y_train.shape[0],1,1)\n",
    "x_test = x_test.reshape(x_test.shape[0],x_test.shape[1],1).permute(0,2,1)\n",
    "y_test = y_test.reshape(y_test.shape[0],1,1)\n",
    "\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "test_ds =  TensorDataset(x_test, y_test)\n",
    "batch_size = 100\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "test_dl = DataLoader(test_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# num_epoch = 10\n",
    "lrate = 2e-3\n",
    "decay = lrate/num_epoch\n",
    "\n",
    "opt = optim.RMSprop(model_vgg.parameters(), lr=lrate)\n",
    "\n",
    "# lambda1 = lambda epoch: (1-decay)*epoch\n",
    "# scheduler = optim.lr_scheduler.LambdaLR(opt, lr_lambda=lambda1)\n",
    "\n",
    "criterion = nn.BCELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1   Train Loss: 0.651   Train Accuracy: 65.33    Test Loss: 0.632   Test Accuracy: 63.40   Time: 0.47sec\n",
      "Epoch:  2   Train Loss: 0.502   Train Accuracy: 76.91    Test Loss: 0.474   Test Accuracy: 79.50   Time: 0.47sec\n",
      "Epoch:  3   Train Loss: 0.452   Train Accuracy: 80.15    Test Loss: 0.457   Test Accuracy: 80.05   Time: 0.46sec\n",
      "Epoch:  4   Train Loss: 0.441   Train Accuracy: 80.70    Test Loss: 0.443   Test Accuracy: 80.85   Time: 0.46sec\n",
      "Epoch:  5   Train Loss: 0.438   Train Accuracy: 80.79    Test Loss: 0.474   Test Accuracy: 78.80   Time: 0.49sec\n",
      "Epoch:  6   Train Loss: 0.425   Train Accuracy: 81.61    Test Loss: 0.453   Test Accuracy: 79.75   Time: 0.46sec\n",
      "Epoch:  7   Train Loss: 0.420   Train Accuracy: 81.83    Test Loss: 0.428   Test Accuracy: 82.25   Time: 0.44sec\n",
      "Epoch:  8   Train Loss: 0.417   Train Accuracy: 82.08    Test Loss: 0.427   Test Accuracy: 81.85   Time: 0.46sec\n",
      "Epoch:  9   Train Loss: 0.412   Train Accuracy: 82.29    Test Loss: 0.426   Test Accuracy: 81.60   Time: 0.46sec\n",
      "Epoch: 10   Train Loss: 0.408   Train Accuracy: 82.28    Test Loss: 0.419   Test Accuracy: 82.20   Time: 0.48sec\n",
      "Epoch: 11   Train Loss: 0.404   Train Accuracy: 82.72    Test Loss: 0.407   Test Accuracy: 83.10   Time: 0.48sec\n",
      "Epoch: 12   Train Loss: 0.395   Train Accuracy: 83.40    Test Loss: 0.405   Test Accuracy: 83.45   Time: 0.47sec\n",
      "Epoch: 13   Train Loss: 0.397   Train Accuracy: 83.19    Test Loss: 0.400   Test Accuracy: 83.45   Time: 0.47sec\n",
      "Epoch: 14   Train Loss: 0.391   Train Accuracy: 83.54    Test Loss: 0.402   Test Accuracy: 83.05   Time: 0.45sec\n",
      "Epoch: 15   Train Loss: 0.390   Train Accuracy: 83.56    Test Loss: 0.392   Test Accuracy: 84.10   Time: 0.51sec\n",
      "Epoch: 16   Train Loss: 0.384   Train Accuracy: 83.78    Test Loss: 0.401   Test Accuracy: 82.90   Time: 0.45sec\n",
      "Epoch: 17   Train Loss: 0.384   Train Accuracy: 83.84    Test Loss: 0.396   Test Accuracy: 83.05   Time: 0.48sec\n",
      "Epoch: 18   Train Loss: 0.380   Train Accuracy: 83.90    Test Loss: 0.394   Test Accuracy: 84.00   Time: 0.75sec\n",
      "Epoch: 19   Train Loss: 0.379   Train Accuracy: 84.19    Test Loss: 0.407   Test Accuracy: 82.45   Time: 0.73sec\n",
      "Epoch: 20   Train Loss: 0.376   Train Accuracy: 84.29    Test Loss: 0.396   Test Accuracy: 83.05   Time: 0.58sec\n",
      "Epoch: 21   Train Loss: 0.374   Train Accuracy: 84.28    Test Loss: 0.393   Test Accuracy: 83.45   Time: 0.57sec\n",
      "Epoch: 22   Train Loss: 0.374   Train Accuracy: 84.50    Test Loss: 0.381   Test Accuracy: 84.30   Time: 0.64sec\n",
      "Epoch: 23   Train Loss: 0.377   Train Accuracy: 84.41    Test Loss: 0.380   Test Accuracy: 84.45   Time: 0.54sec\n",
      "Epoch: 24   Train Loss: 0.373   Train Accuracy: 84.46    Test Loss: 0.382   Test Accuracy: 84.70   Time: 0.61sec\n",
      "Epoch: 25   Train Loss: 0.371   Train Accuracy: 84.80    Test Loss: 0.381   Test Accuracy: 84.35   Time: 0.63sec\n",
      "Epoch: 26   Train Loss: 0.369   Train Accuracy: 84.54    Test Loss: 0.383   Test Accuracy: 84.60   Time: 0.55sec\n",
      "Epoch: 27   Train Loss: 0.369   Train Accuracy: 84.38    Test Loss: 0.397   Test Accuracy: 83.20   Time: 0.61sec\n",
      "Epoch: 28   Train Loss: 0.368   Train Accuracy: 84.72    Test Loss: 0.376   Test Accuracy: 84.40   Time: 0.59sec\n",
      "Epoch: 29   Train Loss: 0.364   Train Accuracy: 84.95    Test Loss: 0.377   Test Accuracy: 84.50   Time: 0.64sec\n",
      "Epoch: 30   Train Loss: 0.365   Train Accuracy: 84.64    Test Loss: 0.377   Test Accuracy: 84.05   Time: 0.59sec\n",
      "Epoch: 31   Train Loss: 0.365   Train Accuracy: 84.72    Test Loss: 0.372   Test Accuracy: 84.90   Time: 0.67sec\n",
      "Epoch: 32   Train Loss: 0.366   Train Accuracy: 84.65    Test Loss: 0.378   Test Accuracy: 84.00   Time: 0.61sec\n",
      "Epoch: 33   Train Loss: 0.362   Train Accuracy: 85.19    Test Loss: 0.374   Test Accuracy: 84.60   Time: 0.57sec\n",
      "Epoch: 34   Train Loss: 0.361   Train Accuracy: 85.12    Test Loss: 0.374   Test Accuracy: 84.75   Time: 0.62sec\n",
      "Epoch: 35   Train Loss: 0.361   Train Accuracy: 85.25    Test Loss: 0.370   Test Accuracy: 84.70   Time: 0.59sec\n",
      "Epoch: 36   Train Loss: 0.359   Train Accuracy: 85.14    Test Loss: 0.375   Test Accuracy: 84.00   Time: 0.55sec\n",
      "Epoch: 37   Train Loss: 0.358   Train Accuracy: 85.09    Test Loss: 0.367   Test Accuracy: 84.40   Time: 0.57sec\n",
      "Epoch: 38   Train Loss: 0.357   Train Accuracy: 85.17    Test Loss: 0.374   Test Accuracy: 84.25   Time: 0.62sec\n",
      "Epoch: 39   Train Loss: 0.355   Train Accuracy: 85.26    Test Loss: 0.368   Test Accuracy: 84.85   Time: 0.57sec\n",
      "Epoch: 40   Train Loss: 0.356   Train Accuracy: 85.15    Test Loss: 0.402   Test Accuracy: 82.85   Time: 0.54sec\n",
      "Epoch: 41   Train Loss: 0.352   Train Accuracy: 85.36    Test Loss: 0.365   Test Accuracy: 85.15   Time: 0.58sec\n",
      "Epoch: 42   Train Loss: 0.353   Train Accuracy: 85.21    Test Loss: 0.370   Test Accuracy: 85.10   Time: 0.58sec\n",
      "Epoch: 43   Train Loss: 0.351   Train Accuracy: 85.41    Test Loss: 0.369   Test Accuracy: 84.60   Time: 0.65sec\n",
      "Epoch: 44   Train Loss: 0.352   Train Accuracy: 85.47    Test Loss: 0.366   Test Accuracy: 85.45   Time: 0.57sec\n",
      "Epoch: 45   Train Loss: 0.350   Train Accuracy: 85.22    Test Loss: 0.364   Test Accuracy: 85.50   Time: 0.63sec\n",
      "Epoch: 46   Train Loss: 0.346   Train Accuracy: 85.38    Test Loss: 0.360   Test Accuracy: 85.30   Time: 0.60sec\n",
      "Epoch: 47   Train Loss: 0.346   Train Accuracy: 85.45    Test Loss: 0.369   Test Accuracy: 85.15   Time: 0.57sec\n",
      "Epoch: 48   Train Loss: 0.347   Train Accuracy: 85.29    Test Loss: 0.363   Test Accuracy: 85.25   Time: 0.62sec\n",
      "Epoch: 49   Train Loss: 0.344   Train Accuracy: 85.69    Test Loss: 0.368   Test Accuracy: 85.40   Time: 0.59sec\n",
      "Epoch: 50   Train Loss: 0.346   Train Accuracy: 85.64    Test Loss: 0.362   Test Accuracy: 85.40   Time: 0.57sec\n",
      "Epoch: 51   Train Loss: 0.343   Train Accuracy: 85.58    Test Loss: 0.374   Test Accuracy: 84.70   Time: 0.64sec\n",
      "Epoch: 52   Train Loss: 0.342   Train Accuracy: 85.81    Test Loss: 0.372   Test Accuracy: 84.50   Time: 0.60sec\n",
      "Epoch: 53   Train Loss: 0.344   Train Accuracy: 85.59    Test Loss: 0.387   Test Accuracy: 83.85   Time: 0.64sec\n",
      "Epoch: 54   Train Loss: 0.339   Train Accuracy: 85.84    Test Loss: 0.363   Test Accuracy: 85.60   Time: 0.57sec\n",
      "Epoch: 55   Train Loss: 0.340   Train Accuracy: 85.69    Test Loss: 0.359   Test Accuracy: 85.60   Time: 0.68sec\n",
      "Epoch: 56   Train Loss: 0.338   Train Accuracy: 85.83    Test Loss: 0.358   Test Accuracy: 85.05   Time: 0.72sec\n",
      "Epoch: 57   Train Loss: 0.336   Train Accuracy: 86.03    Test Loss: 0.368   Test Accuracy: 84.65   Time: 0.72sec\n",
      "Epoch: 58   Train Loss: 0.337   Train Accuracy: 85.99    Test Loss: 0.359   Test Accuracy: 85.05   Time: 0.73sec\n",
      "Epoch: 59   Train Loss: 0.338   Train Accuracy: 85.69    Test Loss: 0.368   Test Accuracy: 85.05   Time: 0.73sec\n",
      "Epoch: 60   Train Loss: 0.337   Train Accuracy: 85.78    Test Loss: 0.357   Test Accuracy: 85.25   Time: 0.62sec\n",
      "Epoch: 61   Train Loss: 0.337   Train Accuracy: 85.84    Test Loss: 0.358   Test Accuracy: 85.50   Time: 0.68sec\n",
      "Epoch: 62   Train Loss: 0.337   Train Accuracy: 86.16    Test Loss: 0.362   Test Accuracy: 85.45   Time: 0.57sec\n",
      "Epoch: 63   Train Loss: 0.333   Train Accuracy: 86.24    Test Loss: 0.358   Test Accuracy: 85.70   Time: 0.64sec\n",
      "Epoch: 64   Train Loss: 0.334   Train Accuracy: 86.05    Test Loss: 0.358   Test Accuracy: 85.05   Time: 0.60sec\n",
      "Epoch: 65   Train Loss: 0.334   Train Accuracy: 86.06    Test Loss: 0.360   Test Accuracy: 85.25   Time: 0.56sec\n",
      "Epoch: 66   Train Loss: 0.335   Train Accuracy: 86.19    Test Loss: 0.357   Test Accuracy: 85.55   Time: 0.58sec\n",
      "Epoch: 67   Train Loss: 0.330   Train Accuracy: 86.12    Test Loss: 0.359   Test Accuracy: 85.50   Time: 0.61sec\n",
      "Epoch: 68   Train Loss: 0.334   Train Accuracy: 85.76    Test Loss: 0.358   Test Accuracy: 85.30   Time: 0.57sec\n",
      "Epoch: 69   Train Loss: 0.331   Train Accuracy: 86.31    Test Loss: 0.361   Test Accuracy: 85.00   Time: 0.58sec\n",
      "Epoch: 70   Train Loss: 0.331   Train Accuracy: 86.08    Test Loss: 0.363   Test Accuracy: 85.00   Time: 0.66sec\n",
      "Epoch: 71   Train Loss: 0.330   Train Accuracy: 86.00    Test Loss: 0.357   Test Accuracy: 85.35   Time: 0.63sec\n",
      "Epoch: 72   Train Loss: 0.330   Train Accuracy: 86.08    Test Loss: 0.355   Test Accuracy: 85.60   Time: 0.58sec\n",
      "Epoch: 73   Train Loss: 0.330   Train Accuracy: 86.12    Test Loss: 0.356   Test Accuracy: 85.65   Time: 0.70sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 74   Train Loss: 0.329   Train Accuracy: 86.14    Test Loss: 0.355   Test Accuracy: 85.55   Time: 1.33sec\n",
      "Epoch: 75   Train Loss: 0.329   Train Accuracy: 85.86    Test Loss: 0.357   Test Accuracy: 85.40   Time: 0.91sec\n",
      "Epoch: 76   Train Loss: 0.329   Train Accuracy: 86.14    Test Loss: 0.354   Test Accuracy: 85.60   Time: 0.67sec\n",
      "Epoch: 77   Train Loss: 0.327   Train Accuracy: 86.38    Test Loss: 0.355   Test Accuracy: 85.65   Time: 0.64sec\n",
      "Epoch: 78   Train Loss: 0.329   Train Accuracy: 86.11    Test Loss: 0.358   Test Accuracy: 85.30   Time: 0.62sec\n",
      "Epoch: 79   Train Loss: 0.330   Train Accuracy: 86.22    Test Loss: 0.353   Test Accuracy: 85.80   Time: 0.65sec\n",
      "Epoch: 80   Train Loss: 0.329   Train Accuracy: 86.24    Test Loss: 0.363   Test Accuracy: 84.85   Time: 0.60sec\n",
      "Epoch: 81   Train Loss: 0.326   Train Accuracy: 86.49    Test Loss: 0.360   Test Accuracy: 85.10   Time: 0.82sec\n",
      "Epoch: 82   Train Loss: 0.327   Train Accuracy: 86.09    Test Loss: 0.361   Test Accuracy: 85.15   Time: 0.84sec\n",
      "Epoch: 83   Train Loss: 0.324   Train Accuracy: 86.31    Test Loss: 0.365   Test Accuracy: 85.05   Time: 0.63sec\n",
      "Epoch: 84   Train Loss: 0.324   Train Accuracy: 86.49    Test Loss: 0.362   Test Accuracy: 85.20   Time: 0.70sec\n",
      "Epoch: 85   Train Loss: 0.324   Train Accuracy: 86.31    Test Loss: 0.381   Test Accuracy: 83.80   Time: 0.70sec\n",
      "Epoch: 86   Train Loss: 0.321   Train Accuracy: 86.55    Test Loss: 0.373   Test Accuracy: 84.00   Time: 0.66sec\n",
      "Epoch: 87   Train Loss: 0.324   Train Accuracy: 86.20    Test Loss: 0.357   Test Accuracy: 85.20   Time: 0.67sec\n",
      "Epoch: 88   Train Loss: 0.323   Train Accuracy: 86.49    Test Loss: 0.365   Test Accuracy: 84.50   Time: 0.97sec\n",
      "Epoch: 89   Train Loss: 0.322   Train Accuracy: 86.46    Test Loss: 0.355   Test Accuracy: 85.70   Time: 0.73sec\n",
      "Epoch: 90   Train Loss: 0.325   Train Accuracy: 86.51    Test Loss: 0.369   Test Accuracy: 84.85   Time: 0.67sec\n",
      "Epoch: 91   Train Loss: 0.321   Train Accuracy: 86.50    Test Loss: 0.356   Test Accuracy: 85.25   Time: 0.57sec\n",
      "Epoch: 92   Train Loss: 0.323   Train Accuracy: 86.49    Test Loss: 0.366   Test Accuracy: 84.65   Time: 0.65sec\n",
      "Epoch: 93   Train Loss: 0.321   Train Accuracy: 86.49    Test Loss: 0.355   Test Accuracy: 85.55   Time: 0.65sec\n",
      "Epoch: 94   Train Loss: 0.319   Train Accuracy: 86.59    Test Loss: 0.358   Test Accuracy: 85.30   Time: 0.52sec\n",
      "Epoch: 95   Train Loss: 0.322   Train Accuracy: 86.47    Test Loss: 0.355   Test Accuracy: 85.40   Time: 0.63sec\n",
      "Epoch: 96   Train Loss: 0.322   Train Accuracy: 86.59    Test Loss: 0.362   Test Accuracy: 85.15   Time: 0.69sec\n",
      "Epoch: 97   Train Loss: 0.318   Train Accuracy: 86.58    Test Loss: 0.364   Test Accuracy: 85.60   Time: 0.80sec\n",
      "Epoch: 98   Train Loss: 0.321   Train Accuracy: 86.50    Test Loss: 0.355   Test Accuracy: 85.40   Time: 0.81sec\n",
      "Epoch: 99   Train Loss: 0.317   Train Accuracy: 86.80    Test Loss: 0.357   Test Accuracy: 85.60   Time: 0.94sec\n",
      "Epoch: 100   Train Loss: 0.318   Train Accuracy: 86.64    Test Loss: 0.358   Test Accuracy: 85.80   Time: 0.92sec\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "import time\n",
    "\n",
    "\n",
    "num_epoch = 100\n",
    "\n",
    "a_tr_loss = np.zeros([num_epoch])\n",
    "a_tr_accuracy = np.zeros([num_epoch])\n",
    "a_ts_loss = np.zeros([num_epoch])\n",
    "a_ts_accuracy = np.zeros([num_epoch])\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    correct = 0 # initialize error counter\n",
    "    total = 0 # initialize total counter\n",
    "    batch_loss = []\n",
    "    tic = time.time()\n",
    "    \n",
    "    model_vgg.train() # put model in training mode\n",
    "    # iterate over training set\n",
    "    for train_iter, data in enumerate(train_dl):\n",
    "        x_batch,y_batch = data\n",
    "        y_batch = y_batch.view(-1,1)\n",
    "        out = model_vgg(x_batch)\n",
    "#         print(\"y_batch \",y_batch)\n",
    "        # Compute Loss\n",
    "#         print(y_batch.shape)\n",
    "        loss = criterion(out,y_batch.type(torch.float))\n",
    "        batch_loss.append(loss.item())\n",
    "        # Zero gradients\n",
    "        opt.zero_grad()\n",
    "        # Compute gradients using back propagation\n",
    "        loss.backward()\n",
    "        # Take an optimization 'step'\n",
    "        opt.step()\n",
    "        predicted = out.clamp(0,1).round().type(torch.long)\n",
    "#         print(\"predicted: \",predicted)\n",
    "        total += y_batch.size(0)\n",
    "        correct += (predicted == y_batch).sum().item()\n",
    "        \n",
    "    a_tr_loss[epoch] = np.mean(batch_loss) # Compute average loss over epoch\n",
    "    a_tr_accuracy[epoch] = 100*correct/total\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    batch_loss = []\n",
    "    model_vgg.eval() # put model in evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for data in test_dl:\n",
    "            images, labels = data\n",
    "            labels = labels.view(-1,1)\n",
    "            out = model_vgg(images)\n",
    "            batch_loss.append(criterion(out,labels.type(torch.float)).item())\n",
    "            predicted = out.clamp(0,1).round().type(torch.long)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "    a_ts_loss[epoch] = np.mean(batch_loss)\n",
    "    a_ts_accuracy[epoch] = 100*correct/total\n",
    "    elapsed = time.time()-tic\n",
    "    \n",
    "    # Print details every print_mod epoch\n",
    "    print('Epoch: {0:2d}   Train Loss: {1:.3f}   '.format(epoch+1, a_tr_loss[epoch])\n",
    "          +'Train Accuracy: {0:.2f}    Test Loss: {1:.3f}   '.format(a_tr_accuracy[epoch], a_ts_loss[epoch])\n",
    "          +'Test Accuracy: {0:.2f}   '.format(a_ts_accuracy[epoch])\n",
    "          +'Time: {0:.2f}sec'.format(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training auc =  0.9199856429850293\n",
      "test label confidences saved in yts_hat_pytorch.csv\n"
     ]
    }
   ],
   "source": [
    "# generate kaggle submission file using the validation script\n",
    "# !python {\"validation.py \" + model_savepath + \" --Xts_path \" + Xts_savepath + \" --Xtr_path \" + Xtr_savepath + \" --yts_hat_path \" + yts_hat_savepath } "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model when uploaded to kaggle showed bad AUC score. This is because performance was degraded when CNN was tried on this dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
